{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KITTI 3D Object Detection - Data Exploration and Visualization\n",
    "\n",
    "This notebook provides comprehensive data exploration, visualization, and analysis for the KITTI 3D object detection dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from config import cfg\n",
    "from dataset import KITTIDataset, build_transforms\n",
    "\n",
    "# Set style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "dataset = KITTIDataset(\n",
    "    root=cfg.DATA_ROOT,\n",
    "    split=\"training\",\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "print(f\"Image directory: {dataset.image_dir}\")\n",
    "print(f\"Label directory: {dataset.label_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect all 3D box parameters\n",
    "all_boxes = []\n",
    "for i in range(len(dataset)):\n",
    "    _, target, _ = dataset[i]\n",
    "    if target.sum() != 0:  # Skip empty targets\n",
    "        all_boxes.append(target.numpy())\n",
    "\n",
    "all_boxes = np.array(all_boxes)\n",
    "print(f\"Valid samples with Car objects: {len(all_boxes)}\")\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(all_boxes, columns=['x', 'y', 'z', 'length', 'width', 'height', 'rotation_y'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "print(\"\\n=== Statistical Summary ===\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots\n",
    "fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "fig.suptitle('Distribution of 3D Box Parameters', fontsize=16, fontweight='bold')\n",
    "\n",
    "columns = ['x', 'y', 'z', 'length', 'width', 'height', 'rotation_y']\n",
    "for idx, col in enumerate(columns):\n",
    "    row = idx // 4\n",
    "    col_idx = idx % 4\n",
    "    axes[row, col_idx].hist(df[col], bins=50, edgecolor='black', alpha=0.7)\n",
    "    axes[row, col_idx].set_title(f'{col.capitalize()} Distribution')\n",
    "    axes[row, col_idx].set_xlabel(col)\n",
    "    axes[row, col_idx].set_ylabel('Frequency')\n",
    "    axes[row, col_idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove empty subplot\n",
    "fig.delaxes(axes[1, 3])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'parameter_distributions.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Matrix of 3D Box Parameters', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'correlation_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dimensionality Reduction - PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize data\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(df)\n",
    "\n",
    "# Apply PCA\n",
    "pca = PCA()\n",
    "pca_result = pca.fit_transform(data_scaled)\n",
    "\n",
    "# Explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Plot explained variance\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "ax1.bar(range(1, len(explained_variance)+1), explained_variance, alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Principal Component')\n",
    "ax1.set_ylabel('Explained Variance Ratio')\n",
    "ax1.set_title('PCA - Explained Variance by Component')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "ax2.plot(range(1, len(cumulative_variance)+1), cumulative_variance, 'bo-', linewidth=2)\n",
    "ax2.axhline(y=0.95, color='r', linestyle='--', label='95% Variance')\n",
    "ax2.set_xlabel('Number of Components')\n",
    "ax2.set_ylabel('Cumulative Explained Variance')\n",
    "ax2.set_title('PCA - Cumulative Explained Variance')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'pca_variance.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nVariance explained by first 3 components: {cumulative_variance[2]:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D PCA visualization\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], \n",
    "                     c=df['z'], cmap='viridis', alpha=0.6, edgecolors='black', linewidth=0.5)\n",
    "plt.colorbar(scatter, label='Depth (z)')\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "plt.title('PCA - First Two Principal Components (colored by depth)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'pca_2d.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dimensionality Reduction - t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply t-SNE (on subset for speed)\n",
    "subset_size = min(1000, len(data_scaled))\n",
    "indices = np.random.choice(len(data_scaled), subset_size, replace=False)\n",
    "data_subset = data_scaled[indices]\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "tsne_result = tsne.fit_transform(data_subset)\n",
    "\n",
    "# Visualize t-SNE\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(tsne_result[:, 0], tsne_result[:, 1], \n",
    "                     c=df.iloc[indices]['z'], cmap='plasma', alpha=0.6, \n",
    "                     edgecolors='black', linewidth=0.5)\n",
    "plt.colorbar(scatter, label='Depth (z)')\n",
    "plt.xlabel('t-SNE Component 1')\n",
    "plt.ylabel('t-SNE Component 2')\n",
    "plt.title('t-SNE Visualization (colored by depth)', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'tsne_2d.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Clustering Analysis - K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elbow method for optimal K\n",
    "inertias = []\n",
    "K_range = range(2, 11)\n",
    "\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(data_scaled)\n",
    "    inertias.append(kmeans.inertia_)\n",
    "\n",
    "# Plot elbow curve\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(K_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Number of Clusters (K)')\n",
    "plt.ylabel('Inertia (Within-cluster sum of squares)')\n",
    "plt.title('K-Means Elbow Method', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'kmeans_elbow.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply K-Means with optimal K\n",
    "optimal_k = 4\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "clusters = kmeans.fit_predict(data_scaled)\n",
    "\n",
    "# Visualize clusters in PCA space\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], \n",
    "                     c=clusters, cmap='tab10', alpha=0.6, \n",
    "                     edgecolors='black', linewidth=0.5)\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "plt.title(f'K-Means Clustering (K={optimal_k}) in PCA Space', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'kmeans_clusters.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Cluster statistics\n",
    "df['cluster'] = clusters\n",
    "print(\"\\n=== Cluster Statistics ===\")\n",
    "print(df.groupby('cluster').mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Clustering Analysis - DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply DBSCAN\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)\n",
    "dbscan_clusters = dbscan.fit_predict(data_scaled)\n",
    "\n",
    "n_clusters = len(set(dbscan_clusters)) - (1 if -1 in dbscan_clusters else 0)\n",
    "n_noise = list(dbscan_clusters).count(-1)\n",
    "\n",
    "print(f\"Number of clusters: {n_clusters}\")\n",
    "print(f\"Number of noise points: {n_noise}\")\n",
    "\n",
    "# Visualize DBSCAN clusters\n",
    "plt.figure(figsize=(10, 8))\n",
    "scatter = plt.scatter(pca_result[:, 0], pca_result[:, 1], \n",
    "                     c=dbscan_clusters, cmap='tab10', alpha=0.6, \n",
    "                     edgecolors='black', linewidth=0.5)\n",
    "plt.colorbar(scatter, label='Cluster (-1 = noise)')\n",
    "plt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "plt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "plt.title(f'DBSCAN Clustering in PCA Space', fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'dbscan_clusters.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Sample Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample images with 3D boxes\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('Sample Images with 3D Bounding Boxes', fontsize=16, fontweight='bold')\n",
    "\n",
    "sample_indices = np.random.choice(len(dataset), 6, replace=False)\n",
    "\n",
    "for idx, ax in enumerate(axes.flat):\n",
    "    img_idx = sample_indices[idx]\n",
    "    image, target, img_name = dataset[img_idx]\n",
    "    \n",
    "    # Convert tensor to numpy\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = image.numpy().transpose(1, 2, 0)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    ax.set_title(f'Sample {img_idx}: {img_name}')\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Add 3D box info as text\n",
    "    if target.sum() != 0:\n",
    "        info_text = f\"Depth: {target[2]:.1f}m\\nSize: {target[3]:.1f}x{target[4]:.1f}x{target[5]:.1f}m\"\n",
    "        ax.text(0.02, 0.98, info_text, transform=ax.transAxes, \n",
    "               fontsize=8, verticalalignment='top',\n",
    "               bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'sample_images.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Feature Engineering Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create additional features\n",
    "df['volume'] = df['length'] * df['width'] * df['height']\n",
    "df['aspect_ratio'] = df['length'] / df['width']\n",
    "df['distance_3d'] = np.sqrt(df['x']**2 + df['y']**2 + df['z']**2)\n",
    "\n",
    "# Visualize new features\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Engineered Features Distribution', fontsize=14, fontweight='bold')\n",
    "\n",
    "axes[0].hist(df['volume'], bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "axes[0].set_title('Volume Distribution')\n",
    "axes[0].set_xlabel('Volume (mÂ³)')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "axes[1].hist(df['aspect_ratio'], bins=50, edgecolor='black', alpha=0.7, color='lightcoral')\n",
    "axes[1].set_title('Aspect Ratio Distribution')\n",
    "axes[1].set_xlabel('Length / Width')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "axes[2].hist(df['distance_3d'], bins=50, edgecolor='black', alpha=0.7, color='lightgreen')\n",
    "axes[2].set_title('3D Distance Distribution')\n",
    "axes[2].set_xlabel('Distance (m)')\n",
    "axes[2].set_ylabel('Frequency')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(cfg.VIS_DIR, 'engineered_features.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "summary = {\n",
    "    'Total Samples': len(dataset),\n",
    "    'Valid Car Objects': len(all_boxes),\n",
    "    'Average Depth (z)': df['z'].mean(),\n",
    "    'Average Length': df['length'].mean(),\n",
    "    'Average Width': df['width'].mean(),\n",
    "    'Average Height': df['height'].mean(),\n",
    "    'PCA Components for 95% Variance': np.argmax(cumulative_variance >= 0.95) + 1,\n",
    "    'Optimal K-Means Clusters': optimal_k,\n",
    "    'DBSCAN Clusters': n_clusters,\n",
    "    'DBSCAN Noise Points': n_noise\n",
    "}\n",
    "\n",
    "print(\"\\n=== Dataset Summary ===\")\n",
    "for key, value in summary.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"{key}: {value:.2f}\")\n",
    "    else:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "# Save summary to file\n",
    "with open(os.path.join(cfg.LOG_DIR, 'data_exploration_summary.txt'), 'w') as f:\n",
    "    f.write(\"=== Dataset Exploration Summary ===\\n\\n\")\n",
    "    for key, value in summary.items():\n",
    "        if isinstance(value, float):\n",
    "            f.write(f\"{key}: {value:.2f}\\n\")\n",
    "        else:\n",
    "            f.write(f\"{key}: {value}\\n\")\n",
    "\n",
    "print(\"\\nSummary saved to:\", os.path.join(cfg.LOG_DIR, 'data_exploration_summary.txt'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
